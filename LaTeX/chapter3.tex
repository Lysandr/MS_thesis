% !TEX root = main.tex
\chapter{Convex Formulation}
\label{convex}

Now the convex form of Problem 1 shall be derived. The non-convex continuous free-final-time problem is converted into a convex fixed-final-time problem. This will be a second order cone sub-problem. This sub-problem is solved repeatedly to convergence or ``successively.'' This successive process turns each subproblem into a larger free-final-time algorithm.

\section{Linearization}
Let us define the state vector $\mathbf{x}(t) \in \mathbb{R}^{14\times 1}$ and our control vector $\mathbf{u}(t) \in \mathbb{R}^{3\times 1}$:
\begin{align}
& \mathbf{x}(t) \triangleq 
	\begin{bmatrix}
	m(t) & ^\mathcal{N}\mathbf{r}^T(t) & ^\mathcal{N}\mathbf{v}^T(t) & \boldsymbol{\sigma}_\mathcal{B/N}^T(t) & ^\mathcal{B}\bm{\omega}_\mathcal{B/N}^T(t)   
	\end{bmatrix}^T \\
& \mathbf{u}(t) \triangleq \ ^\mathcal{B}\mathbf{F}_{th}(t)  
\end{align}
Therefore the nonlinear dynamics can be expressed in the following form:
\begin{align}
& \frac{d}{dt}\mathbf{x}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) =  
	\begin{bmatrix}
	\dot{m}(t) & ^\mathcal{N}\dot{\mathbf{r}}^T(t) & ^\mathcal{N}\dot{\mathbf{v}}^T(t) & \dot{\boldsymbol{\sigma}}_\mathcal{B/N}^T(t) & ^\mathcal{B}\dot{\bm{\omega}}_\mathcal{B/N}^T(t)  
	\end{bmatrix}^T
\end{align}

In order to formulate our guidance problem with a free-final-time objective, time dilation is introduced. Let us evaluate our dynamics on a normalized trajectory time variable $\tau \in [0,1]$. No matter the resolution of the optimization, the terminal value will end at $\tau = 1$. A differentiation based on this variable is then used to scale the time back and forth, leaving the unscaled final time as an optimization variable. Applying the chain rule of differentiation: 
\begin{align}
& \mathbf{f}(\mathbf{x}(t) , \mathbf{u}(t)) =  \frac{d}{dt}\mathbf{x}(t) = \frac{d\tau}{dt} \frac{d}{d\tau}\mathbf{x}(t) =  \frac{1}{\eta}\frac{d}{d\tau}\mathbf{x}(t)
\end{align}
Let us now translate between the two by using the dilation coefficient $\eta$ which is define as
\begin{align}
& \eta \triangleq \left(\frac{d\tau}{dt}\right)^{-1}
\end{align}

This $\eta$ will become a variable in the convex subproblem that acts as the non-dimensionalized final time. It is a scaling factor that translates between real work differential time and the normalized version used for our algorithm. The nonlinear dynamics, taking advantage of this normalized time, are then written as:
\begin{align}
& \mathbf{x}^\prime(\tau) \triangleq \frac{d}{d\tau}\mathbf{x}(\tau) = \eta \mathbf{f}(\mathbf{x}(\tau), \mathbf{u}(\tau)) = \mathbf{g}(\mathbf{x}(\tau), \mathbf{u}(\tau), \eta)
\end{align}

Taking a first-order Taylor series approximation of the nonlinear dynamics proposed in problem one (\ref{ctproblem}), a linear time-varying system of equations is written to use in our algorithm shown in \ref{taylor}. These dynamics will be instantiated at reference values $(\hat{\mathbf{x}}, \hat{\mathbf{u}}, \hat{\eta})$ at each time, together being referred to as the \textit{linearization path}. 
%
\begin{subequations}
\label{taylor}
\begin{align}
\mathbf{x}^\prime(\tau) 
&= \mathbf{g}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau), \hat{\eta})
+ \frac{\partial \mathbf{g}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\mathbf{x} - \hat{\mathbf{x}}) \ 
+ \frac{\partial \mathbf{g}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\mathbf{u} - \hat{\mathbf{u}}) \ 
+ \frac{\partial \mathbf{g}}{\partial \eta} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\eta - \hat{\eta}) \\
&= \hat{\eta} \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau))
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{x} - \hat{\mathbf{x}}) \
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{u} - \hat{\mathbf{u}}) \
+ \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau)) (\eta - \hat{\eta}) \\
&= {\eta} \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau))
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{x} - \hat{\mathbf{x}}) \
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{u} - \hat{\mathbf{u}}) \\ 
& = \Sigma(\tau)\eta + A(\tau) (\mathbf{x} - \hat{\mathbf{x}}) + B(\tau)(\mathbf{u} - \hat{\mathbf{u}})  \\ 
&= \Sigma(\tau)\eta + A(\tau)\mathbf{x} + B(\tau)\mathbf{u} + \mathbf{z}(\tau)
\end{align}
\end{subequations}

This expression is simplified by breaking the Taylor expansion intro matrix subcomponents. 
\begin{align}
& A(\tau) \triangleq \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}}  \bigg\rvert_{\mathbf{\hat{x}}, \mathbf{\hat{u}}} \\
& B(\tau) \triangleq \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}}  \bigg\rvert_{\mathbf{\hat{x}}, \mathbf{\hat{u}}} \\
& \Sigma(\tau) \triangleq \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau)) \\
& \mathbf{z}(\tau) \triangleq -A(\tau)\mathbf{\hat{x}}- B(\tau)\mathbf{\hat{u}}
\end{align}





\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
\subsection{Convexifying the Minimum Thrust Constraint}
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
Let us now tackle the last source of non-convexity: the non-zero lower bound on actuator thrust. Let us define an $\mathbb{R}^3 \rightarrow \mathbb{R}$ mapping function: $g(\mathbf{u}(\tau)) = F_{min} - \norm{\mathbf{u}(\tau)}_2 \leq 0$. Taking the first order Taylor series linear approximation, the following convexified constraint formulation becomes:
%
\begin{align}
	g(\mathbf{u}(\tau)) &= F_{min} - \norm{\hat{\mathbf{u}}(\tau)} - \frac{\hat{\mathbf{u}}(\tau)^T}{\norm{\hat{\mathbf{u}}(\tau)}}(\mathbf{u}(\tau) - \hat{\mathbf{u}}(\tau)) & \leq 0 \\
	&= F_{min} - \frac{\hat{\mathbf{u}}(\tau)^T}{\norm{\hat{\mathbf{u}}(\tau)}} \mathbf{u}(\tau)  & \leq 0\\
	&= F_{min} - \Xi(\tau)\mathbf{u}(\tau)  & \leq 0
\end{align}
this leads us to the linear, convexified constraint $F_{min} \leq \Xi(\tau)\mathbf{u}(\tau)$ requiring the linearization path value $\hat{\mathbf{u}}(\tau)$. This means that each iteration of the algorithm will use the input sequence path from the previous iteration to satisfy this constraint.







\section{Discretization Scheme}
The final step to fitting the dynamics, state, and control constraints to an optimization form is to cast the problem as a finite dimensional discretization. This finite dimensional problem is chosen to occur over $K\in\mathbb{Z}$ evenly separated points with respect to the normalized trajectory time $\tau$. The index set is defined as $\mathcal{K}\in\mathbb{Z}^{K}$ and $\mathcal{K}_-\in\mathbb{Z}^{K-1}$ for the state and input histories as the following:
\begin{align*}
	\mathcal{K} &\triangleq \{0,1,\cdots, K-1\} \\
	\mathcal{K}_- &\triangleq \{0,1,\cdots, K-2 \}
\end{align*}
%
Given that the trajectory time is normalized on the interval $\tau \in [0,1 ]$, the discrete time step at point $k$ is defined as such:
%
\begin{align}
& \tau_k \triangleq \frac{k}{K-1}, \quad \forall k \in \mathcal{K}
\end{align}
%
For the sake of implementation, a first-order-hold linear scaling is applied to the controls for each time step. Over the interval $\tau \in [\tau_k, \tau_{k+1}]$, the $\mathbf{u}(\tau)$ is expressed in terms of the $\mathbf{u}_k$
 and $\mathbf{u}_{k+1}$:
\begin{equation}
	\mathbf{u}(\tau) \triangleq \alpha_k(\tau) \mathbf{u}_k + \beta(\tau) \mathbf{u}_{k+1}
\end{equation}
%
The input is spread linearly, on a first order relationship, from the index position $k$ to the next known control value at $k+1$ in the control history. This also allows us to consider controller interpolation scheme a priori if used in a feed forward regime. The successive convexification algorithm was tested with a number of discretization methods on state and input, where first order hold (FOH) and Legendre-Gauss-Radau (LGR) collocation methods were found to be the most amenable \cite{malyuta2019discrete}. These two provided the fastest computation times with good performance.
%
The previously defined constants follow the following form:
\begin{align}
d\tau &= \frac{1}{K-1} \\
\alpha_k(\tau) &= \frac{d\tau - \tau}{d\tau} \\
\beta_k(\tau) &= \frac{\tau}{d\tau}
\end{align}
%

The state transition matrix (STM) of the dynamics $\Phi(\tau_{k+1},\tau_k)$ is used to translate the process from a state at time $k$ to future state at $k+1$. This matrix assumes no input is being imparted, but a convolution can be used to describe the time varying input. The STM follows the dynamics:
%
\begin{align}
& \frac{d}{d\tau} \Phi(\tau,\tau_k) = A(\tau) \Phi(\tau,\tau_k), \quad \forall k \in \mathcal{K}
\end{align}
Additionally, the STM has the semigroup, inverse, and identity properties which become useful in the derivation:
\begin{align}
	\Phi(t,s) &= \Phi(t, \gamma)\Phi(\gamma, s) \\
	\Phi(t,s)^{-1} &= \Phi(s,t) \\
	\Phi(s,s) &= \mathbb{I}_{n \times n}
\end{align}
for arbitrary timing parameters $t, \gamma, s$. Let us take advantage of this property during the discretization steps to minimize some computation. A general homogeneous solution for a system defined by $\dot{\mathbf{x}}$ using the STM is the following:
%
\begin{align}
	\text{given that} \ \ \mathbf{x}(\tau) &= \Phi(\tau, \tau_k) \mathbf{x}(\tau_k)\\
	\frac{d}{d\tau}\mathbf{x}(\tau) &= \dot{\Phi}(\tau, \tau_k) \mathbf{x}(\tau_k) = A(\tau)\mathbf{x}(\tau) \\ 
	& = A(\tau) \Phi(\tau, \tau_k) \mathbf{x}(\tau_k)
\end{align}
Integration leads to the following fact:
\begin{align}
	\mathbf{x}(\xi) &= \mathbf{x}(\tau_k) + \int_{\tau_k}^\xi A(\xi) \Phi(\xi, \tau_k) \mathbf{x}(\tau_k) d\xi \\
	&= \left( \mathbb{I}_{n\times n} + \int_{\tau_k}^\xi A(\xi) \Phi(\xi, \tau_k) d\xi \right)  \mathbf{x}(\tau_k)
\end{align}
Therefore the arbitrary state transition mapping from time $\tau_k$ to $\xi$ can be represented as the following:
\begin{align}
	\Phi(\xi, \tau_k) = \mathbb{I}_{n\times n} + \int_{\tau_k}^\xi A(\xi) \Phi(\tau, \tau_k) d\xi, \quad \forall \xi \in \ [\tau_k, \tau_{k+1}]
\end{align}

Recall our continuous LTV system dynamics expression $\mathbf{x}^\prime(\tau) =  A(\tau)\mathbf{x} + B(\tau)\mathbf{u} + \mathbf{z}(\tau) + \Sigma(\tau)\eta$. Employing our control FOH, let us form this as the following discrete time system:
\begin{align}
	\mathbf{x}_{k+1} = F_k\mathbf{x_k} + G^-_k\mathbf{u_k} + G^+_k\mathbf{u_{k+1}} + \bar{\mathbf{z}}_k + \bar{\Sigma}_k\eta
\end{align}
Converting the continuous time dynamics to discrete time dynamics, a series of convolution integrals is performed to define the impact of the transformations over each discrete time step. The continuous linear time invariant discretization form is usually written as $G=\int_{0}^{dt} e^{A \tau} d \tau B$, but given the LTV dynamics and our FOH control assumption, this is reformulated as:
%
\begin{subequations}
\label{disc}
 \begin{align}
 F_k &\triangleq  \Phi(\tau_{k+1},\tau_k)\\
 %
 G^-_k &\triangleq \int_{\tau_k}^{\tau_{k+1}}  \Phi(\tau_{k+1},\xi) \alpha_k(\xi)B(\xi) d\xi\\
 %
 &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}}  \Phi^{-1}(\xi,\tau_{k}) \alpha_k(\xi)B(\xi) d\xi\\
 %
 G^+_k &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}}  \Phi^{-1}(\xi,\tau_{k}) \beta_k(\xi)B(\xi) d\xi\\
 %
 \bar{\Sigma}_k &\triangleq  F_k \int_{\tau_k}^{\tau_{k+1}} \Phi^{-1}(\xi,\tau_{k}) \Sigma(\xi) d\xi\\
 %
 \bar{\mathbf{z}}_k &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}} \Phi^{-1}(\xi,\tau_{k}) \mathbf{z}(\xi) d\xi
\end{align}
\end{subequations}

It should be noted that the number of temporal nodes $K$ chosen for this calculation, where $\mathcal{K} \in \mathbb{Z}^K$, does not affect the accuracy of the solution. While the solution is accurate to the problem statement, it may be suboptimal by a small amount to the same problem evaluated at a higher node count $K$. This is visited in the analysis section later in this report; it is shown that, for a typical landing problem, the difference in key objectives is inconsequential. More simply put, an optimization solution where $K=10$ will still accurately land the vehicle within all the constraints defined, but may do so in more time and with larger cost than the same problem solved at $K=25$. However, the former is computed faster and often produces a total cost marginally higher than the better resolution problem. Note that these are effectively two different problems despite having similar objective and constraint formulation.

\section{Successive Form, Trust Regions and Relaxations}

In order to solve a non-convex problem, a sequence of related convex subproblems must be iteratively solved. However, before a concluding framework can be reached, trust regions and dynamic relaxations must be considered. In order to make sure that this successive framework stays bounded and feasible through this convergence process, the divergence of state and inputs must be bounded from one iteration to another. Unbounded problems can arise from constraints that admit an unbounded cost. To mitigate this issue, the cost function is augmented with soft trust regions about the previous iterate's information. Let us define these deviations at iteration $i$ as such:
\begin{align}
& \delta \mathbf{x}_k^i \triangleq \mathbf{x}_k^i - \mathbf{x}_k^{i-1} \\
& \delta \mathbf{u}_k^i \triangleq \mathbf{u}_k^i - \mathbf{u}_k^{i-1}, \quad \forall k \in \mathcal{K}\\
& \delta \eta^i \triangleq \eta^i - \eta^{i-1}
\end{align}

Let us then fabricate the following constraints with $\bm{\bar{\Delta}}^i \in \mathbb{R}^K$ and $\Delta_\eta^i \in \mathbb{R}$
\begin{align}
& \delta \mathbf{x}_k^i \cdot \delta \mathbf{x}_k^i + \delta \mathbf{u}_k^i \cdot \delta \mathbf{u}_k^i \leq \bar{\Delta}_k^i \\
& \delta \eta^i \cdot \delta \eta^i \leq \Delta_\eta^i
\end{align}

Now $w_\Delta^i \norm{{\bar{\Delta}}^i} + w_{\Delta_\eta} ||\Delta_\eta^i ||$ is appended to the cost function to minimize input, state, and final time deviations and keeping their deviation bounded via constraint, where $w_\Delta^i$ and $w_{\Delta_\eta}$ are weighting scalars depending on the preferences of the scenario. Because the norm is bounded, these are considered soft constraints.

Given that the trust regions are centered about previous points $(\mathbf{x}_{k}^{i-1},\mathbf{u}_{k}^{i-1},\eta^{i-1})$, the Jacobian must be evaluated about the nonlinear trajectory beginning at $\mathbf{x}_{k}^{i-1}$. Then the FOH input vector $\mathbf{u}(\tau)$ is used. Doing this $\forall k \in \mathcal{K}$ defines the aforementioned linearization path $(\hat{\mathbf{x}}, \hat{\mathbf{u}}, \hat{\eta})$. 


Dynamic relaxation variable can now be added to discount artificial infeasibility. This is encountered during the convergence process when the linearization becomes infeasible. For example, if the dynamics are linearized about unrealistic conditions, the problem becomes dynamically inconsistent and will not produce solution. The control is modified such that subproblem solutions are guaranteed to have non-empty feasible sets. This is encountered during the first couple iterations of a successive convexification due to poor initial trajectory or time-of-flight estimation. To get rid of this issue, dynamic relaxation is employed, where a slack variable is added to the dynamics in order to ``make room'' for the iteration to proceed. This can also be thought of as a virtual control or dynamic padding. However, one can guess that this will inevitably be something to minimize in the cost function in order to make sure that our final trajectories are as dynamically consistent as possible. Therefore, let us now write our dynamics as follows: 
%
\begin{align}
& \mathbf{x}_{k+1}^i = F_k^i\mathbf{x}_k^i + G^{-,i}_k\mathbf{u}_k^i + G_k^{+,i}\mathbf{u}_{k+1}^i + \bar{\mathbf{z}}^i_k +\bar{\Sigma}_k^i\eta^i + \bm{\nu}_k^i
\end{align}
The right super script $^i$ indicates the iterate of the algorithm, where the subscript $_k$ means the ordered parameter entrance in our array shaped by $\mathcal{K}$.

As $\bm{\nu}$ will be in the augmented cost function, the following virtual control history vector $\in \mathbb{R}^{K-1}$ will be referred to:
\begin{align}
\bm{\nu}^i = 
	\begin{bmatrix}
	{\bm{\nu}_0^i}^T & \cdots & {\bm{\nu}^i_{K-2}}^T 
	\end{bmatrix}^T
\end{align}

The cost function is augmented again with $w_v \norm{\bm{\nu}^i}_1$ so that the magnitude of the entire history of $\bm{\nu}$ is penalized. As the iteration continues, this value is minimized, making the solution more dynamically feasible and true to the linear system. Additionally, the magnitude of this norm is indicative of a final solution in the successive iteration process.

\section{Convex Sub-Problem}
Now that the proposed problem has been linearized and convexified, the components can be assembled as the full free-final-time problem as shown in problem \ref{problem2} where the following objective function is used:
\begin{align}
	\min_{\eta^i, \mathbf{u}_k^i} \quad \eta^i + w_\Delta^i || \bm{\bar{\Delta}}^i ||_2 + w_{\Delta_\eta} || \Delta_\eta^i ||_1 + w_v || \bar{\bm{\nu}}^i ||_1
\end{align}

\section{Algorithm}
The goal is for the successive convexification algorithm \ref{Successive} to continue iterating until $\Delta_{tol}$ and $\nu_{tol}$ are met. These are compared to by the magnitude of each vector and are checked at the end of each iteration of the routine. Additionally, to ensure boundedness on the trust regions and to prevent an admitted unbounded cost, the cost weighting of the trust regions is increased after each iteration.

\begin{algorithm}
\caption{Successive Convexification}\label{Successive}
\begin{algorithmic}[1]
\Procedure{PDG\_SCvx}{$x_{ref}, u_{ref}, \eta_{ref}$}
\State An initial reference trajectory must be generated, as a linearization path for the first iterate of SCVx. In this prototype case, a simple routine which linearly spans many states from initial to terminal condition is performed, although it is recommended to use a more sophisticated approach. The following is used in this demonstration:
\For{$k$ $\in$ $(1:K)$}
\State		$a_1 = (K-k)/K;$
\State		$	a_2 = k/K;$
\State		$	m_k = (a_1*m_0 + a_2*m_K)$
\State		$	r_k = (a_1*r_0 + a_2*r_K)$
\State		$	v_k = (a_1*v_0 + a_2*v_K)$
\State		$	\sigma_k = [0 \ 0 \ 0]^T$
\State		$	\omega_k = [0 \ 0 \ 0]^T$
\State		$	\mathbf{x}[:, k] = [m_k \ r_k \ v_k \ \sigma_k  \ \omega_k]^T$
\State		$	\mathbf{u}[:, k] = -\mathbf{g} * m_k$
\EndFor{}
\While{$ ||{\Delta}|| \geq \Delta_{tol} \quad \&\& \quad ||{\nu}|| \geq \nu_{tol} \quad \&\& \quad i \leq i_{max}$}
\State Compute $\bar{A}_k^{i-1}, \bar{B}_k^{i-1}, \bar{C}_k^{i-1}, \bar{\Sigma}_k^{i-1}, \bar{z}_k^{i-1}$ from $\mathbf{x}_k^{i-1}, \mathbf{u}_k^{i-1}, \eta^{i-1}$
\State Solve \textit{Problem 2} using $\mathbf{x}_k^{i-1}, \mathbf{u}_k^{i-1}, \eta^{i-1}, \bar{A}_k^{i-1}, \bar{B}_k^{i-1}, \bar{C}_k^{i-1}, \bar{\Sigma}_k^{i-1}, \bar{z}_k^{i-1}$
\State Store the newly found $\mathbf{x}_k^{i}, \mathbf{u}_k^{i}, \eta^{i}$ as linearization path for the next iterate.
\State $w^{i+1}_\Delta = 1.7*w^{i}_\Delta$
\If{$i > i_\nu \quad \& \& \quad ||{\nu}|| > \nu_{infeasible}$ }
\State Break out of this guidance loop, as the problem is likely infeasible as proposed.
\State Initialize fault recovery procedure.
\EndIf
\State $i++;$
\EndWhile 
\State \textbf{return} $\mathbf{x}, \mathbf{u}$
\EndProcedure
\end{algorithmic}
\end{algorithm}



\clearpage
\begin{mdframed}
\label{problem2}
\textbf{Problem 2: Discretized Convex Fixed-Final-Time Sub-Problem ($i^{th}$ iteration)}
\underline{Cost Function:}
\begin{equation*}
\min_{\eta^i, \mathbf{u}_k^i} \quad \eta^i + w_\Delta^i || \bm{\bar{\Delta}}^i ||_2 + w_{\Delta_\eta} || \Delta_\eta^i ||_1 + w_v || \bar{\bm{\nu}}^i ||_1
\end{equation*}
%
\underline{Boundary Conditions:}  
\begin{align*}
m_0 &= m_0, &^\mathcal{N}\mathbf{r}_0 &= \mathbf{r}_0, & ^\mathcal{N}\mathbf{v}_0 &= \mathbf{v}_0, & \boldsymbol{\sigma}_{\mathcal{B/N}_0} &= {\boldsymbol{\sigma}_0}, \quad ^\mathcal{B}\boldsymbol{\omega}_{\mathcal{B/N}_0} = \boldsymbol{\omega}_0 \\
\quad ^\mathcal{N}\mathbf{r}_{K-1} &= \mathbf{0}, & ^\mathcal{N}\mathbf{v}_{K-1} &= \mathbf{0}, & \boldsymbol{\sigma}_{\mathcal{B/N}_{K-1}} &= \mathbf{0}, & ^\mathcal{B}\boldsymbol{\omega}_{\mathcal{B/N}_{K-1}} &= \mathbf{0}
\end{align*}
%
\underline{Dynamics:}  
\begin{align*}
& \mathbf{x}_{k+1}^i = F_k^i\mathbf{x}_k^i + G^{-,i}_k\mathbf{u}_k^i + G_k^{+,i}\mathbf{u}_{k+1}^i + \bar{\mathbf{z}}^i_k +\bar{\Sigma}_k^i\eta^i + \bm{\nu}_k^i
\end{align*}
%
\underline{State and Control Constraints:}
\begin{align*}
m_{dry} - m_k & \leq 0 \\
|| [\hat{\bm{n}}_2 \ \ \hat{\bm{n}}_3 ]^T \mathbf{r}_k \lvert\lvert_2 \ \tan{\gamma_{gs}}  - \hat{\bm{n}}_1^T \mathbf{r}_k & \leq 0 \\
%
\left \lVert \boldsymbol{\sigma}_{\mathcal{B/N}_k} \right \lVert_2 &\leq \tan \left( \frac{\psi_{max}}{4} \right) \\
%
|| \bm{\omega}_{\mathcal{B/N}_k} ||_2 & \leq \omega_{max}
\end{align*}
%
\underline{Control Constraints:}  
\begin{align*}
F_{min} &\leq \Xi_k^i\mathbf{u}_k^i \\
|| \mathbf{u}_k^i ||_2 &\leq F_{max} \\
\cos(\delta_{max}) || \mathbf{u}_k^i ||_2 &\leq \hat{\bm{b}}_1^T \mathbf{u}_k^i
% || \delta_{\text{TVC}_{k+1}} - \delta_{\text{TVC}_{k}} ||_2 &\leq \frac{ \eta^i}{K}\dot{\delta}_{\text{TVC}_{max}}
\end{align*}
%
\underline{Trust Regions:}  
\begin{align*}
& ||{\delta \mathbf{x}_k^i}^T  \delta \mathbf{x}_k^i + {\delta \mathbf{u}_k^i}^T \delta \mathbf{u}_k^i ||_2 \leq \bar{\Delta}_k^i \\
& || \delta \eta^i ||_2 \leq \Delta_\eta^i
\end{align*}
\end{mdframed}

