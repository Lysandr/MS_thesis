% !TEX root = main.tex
\chapter{Convex Formulation}
\label{convex}

Now we shall derive the convex form of Problem 1. We will convert the non-convex continuous free-final-time problem to a convex fixed-final-time problem. This will be a second order cone sub-problem. We will solve this sub-problem repeatedly to convergence or "successively." This successive process turns each subproblem into a larger free-final-time algorithm.

\section{Linearization}
Let us define the state vector $\mathbf{x}(t) \in \mathbb{R}^{14\times 1}$ and our control vector $\mathbf{u}(t) \in \mathbb{R}^{3\times 1}$:
\begin{align}
& \mathbf{x}(t) \triangleq 
	\begin{bmatrix}
	m(t) & ^\mathcal{N}\mathbf{r}^T(t) & ^\mathcal{N}\mathbf{v}^T(t) & \boldsymbol{\sigma}_\mathcal{B/N}^T(t) & ^\mathcal{B}\bm{\omega}_\mathcal{B/N}^T(t)   
	\end{bmatrix}^T \\
& \mathbf{u}(t) \triangleq \ ^\mathcal{B}\mathbf{F}_{th}(t)  
\end{align}
Therefore we can express the nonlinear dynamics in the following form
\begin{align}
& \frac{d}{dt}\mathbf{x}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) =  
	\begin{bmatrix}
	\dot{m}(t) & ^\mathcal{N}\dot{\mathbf{r}}^T(t) & ^\mathcal{N}\dot{\mathbf{v}}^T(t) & \dot{\boldsymbol{\sigma}}_\mathcal{B/N}^T(t) & ^\mathcal{B}\dot{\bm{\omega}}_\mathcal{B/N}^T(t)  
	\end{bmatrix}^T
\end{align}

In order to formulate our guidance problem with the free-final-time objective we must introduce time dilation. We can evaluate our dynamics on a normalized trajectory time variable $\tau \in [0,1]$. No matter the resolution of the optimization, the terminal value will end at $\tau = 1$. We can then use a differentiation based on this variable to scale the time back and forth, leaving the unscaled final time as an optimization variable. Applying the chain rule of differentiation: 
\begin{align}
& \mathbf{f}(\mathbf{x}(t) , \mathbf{u}(t)) =  \frac{d}{dt}\mathbf{x}(t) = \frac{d\tau}{dt} \frac{d}{d\tau}\mathbf{x}(t) =  \frac{1}{\eta}\frac{d}{d\tau}\mathbf{x}(t)
\end{align}
We can now translate between the two by using the dilation coefficient $\eta$ which we define as
\begin{align}
& \eta \triangleq \left(\frac{d\tau}{dt}\right)^{-1}
\end{align}

This $\eta$ will become a variable in the convex subproblem that acts as the non-dimensionalized final time. It is a scaling factor that translates between real work differential time and the normalized version used for our algorithm. We can now write the nonlinear dynamics to take advantage of this normalized time:
\begin{align}
& \mathbf{x}^\prime(\tau) \triangleq \frac{d}{d\tau}\mathbf{x}(\tau) = \eta \mathbf{f}(\mathbf{x}(\tau), \mathbf{u}(\tau)) = \mathbf{g}(\mathbf{x}(\tau), \mathbf{u}(\tau), \eta)
\end{align}

Taking a first-order Taylor series approximation of the nonlinear dynamics proposed in Problem one, we can write a linear time-varying framework equations \ref{taylor} for the system to use in our algorithm. These dynamics will be instantiated at reference values $(\hat{\mathbf{x}}, \hat{\mathbf{u}}, \hat{\eta})$ at each time. 
%
\begin{subequations}
\label{taylor}
\begin{align}
\mathbf{x}^\prime(\tau) 
&= \mathbf{g}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau), \hat{\eta})
+ \frac{\partial \mathbf{g}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\mathbf{x} - \hat{\mathbf{x}}) \ 
+ \frac{\partial \mathbf{g}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\mathbf{u} - \hat{\mathbf{u}}) \ 
+ \frac{\partial \mathbf{g}}{\partial \eta} \bigg\rvert_{\hat{x},\hat{u},\hat{\eta}} (\eta - \hat{\eta}) \\
&= \hat{\eta} \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau))
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{x} - \hat{\mathbf{x}}) \
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{u} - \hat{\mathbf{u}}) \
+ \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau)) (\eta - \hat{\eta}) \\
&= {\eta} \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau))
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{x} - \hat{\mathbf{x}}) \
+ \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}} \bigg\rvert_{\hat{x},\hat{u}} (\mathbf{u} - \hat{\mathbf{u}}) \\ 
& = \Sigma(\tau)\eta + A(\tau) (\mathbf{x} - \hat{\mathbf{x}}) + B(\tau)(\mathbf{u} - \hat{\mathbf{u}})  \\ 
&= \Sigma(\tau)\eta + A(\tau)\mathbf{x} + B(\tau)\mathbf{u} + \mathbf{z}(\tau)
\end{align}
\end{subequations}

We can simplify this expression by breaking the Taylor expansion intro matrix subcomponents. 
\begin{align}
& A(\tau) \triangleq \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{x}}  \bigg\rvert_{\mathbf{\hat{x}}, \mathbf{\hat{u}}} \\
& B(\tau) \triangleq \hat{\eta} \frac{\partial \mathbf{f}}{\partial \mathbf{u}}  \bigg\rvert_{\mathbf{\hat{x}}, \mathbf{\hat{u}}} \\
& \Sigma(\tau) \triangleq \mathbf{f}(\hat{\mathbf{x}}(\tau), \hat{\mathbf{u}}(\tau)) \\
& \mathbf{z}(\tau) \triangleq -A(\tau)\mathbf{\hat{x}}- B(\tau)\mathbf{\hat{u}}
\end{align}


\subsection{Convexifying the Minimum Thrust Constraint}
With this done, we tackle the last source of non-convexity: the non-zero lower bound to our actuator thrust. Let us define an $\mathbb{R}^3 \rightarrow \mathbb{R}$ mapping function: $g(\mathbf{u}(\tau)) = F_{min} - \norm{\mathbf{u}(\tau)}_2 \leq 0$. Taking the first order Taylor series linear approximation, we have the following convexified constraint formulation:
%
\begin{align}
	g(\mathbf{u}(\tau)) &= F_{min} - \norm{\hat{\mathbf{u}}(\tau)} - \frac{\hat{\mathbf{u}}(\tau)^T}{\norm{\hat{\mathbf{u}}(\tau)}}(\mathbf{u}(\tau) - \hat{\mathbf{u}}(\tau)) & \leq 0 \\
	&= F_{min} - \frac{\hat{\mathbf{u}}(\tau)^T}{\norm{\hat{\mathbf{u}}(\tau)}} \mathbf{u}(\tau)  & \leq 0\\
	&= F_{min} - \Xi(\tau)\mathbf{u}(\tau)  & \leq 0
\end{align}
this leads us to the linear, convexified constraint $F_{min} \leq \Xi(\tau)\mathbf{u}(\tau)$. Recall the variable $\hat{\mathbf{u}}(\tau)$ is our reference input history.







\section{Discretization Scheme}
The final step to fitting the dynamics, state, and control constraints to an optimization form is to cast the problem as a finite dimensional discretization. We must choose this finite dimensional problem to occur over $K\in\mathbb{Z}$ evenly separated points with respect to the normalized trajectory time $\tau$. We can define the index set $\mathcal{K}\in\mathbb{Z}^{K}$ and $\mathcal{K}_-\in\mathbb{Z}^{K-1}$ for the state and input histories as the following:
\begin{align*}
	\mathcal{K} &\triangleq \{0,1,\cdots, K-1\} \\
	\mathcal{K}_- &\triangleq \{0,1,\cdots, K-2 \}
\end{align*}
%
Given that the trajectory time is normalized on the interval $\tau \in [0,1 ]$, we can define the discrete time step at point $k$ as such
%
\begin{align}
& \tau_k \triangleq \frac{k}{K-1}, \quad \forall k \in \mathcal{K}
\end{align}
%
For implementation sake, a first-order-hold linear scaling on the applied controls for each time step. Over the interval $\tau \in [\tau_k, \tau_{k+1}]$, we express $\mathbf{u}(\tau)$ in terms of the $\mathbf{u}_k$
 and $\mathbf{u}_{k+1}$:
\begin{equation}
	\mathbf{u}(\tau) \triangleq \alpha_k(\tau) \mathbf{u}_k + \beta(\tau) \mathbf{u}_{k+1}
\end{equation}
%
The input is spread linearly, on a first order relationship, from the index position $k$ to the next known control value at $k+1$ in the control history. This also allows us to consider controller interpolation scheme a priori if used in a feed forward regime. The successive convexification algorithm was tested with a number of discretization methods on state and input, where first order hold (FOH) and Legendre-Gauss-Radau (LGR) collocation methods were found to be the most amenable \cite{malyuta2019discrete}. These two provided the fastest computation times with good performance.
%
The constants we have defined follow the following form:
\begin{align}
d\tau &= \frac{1}{K-1} \\
\alpha_k(\tau) &= \frac{d\tau - \tau}{d\tau} \\
\beta_k(\tau) &= \frac{\tau}{d\tau}
\end{align}
%

We use the state transition matrix (STM) of the dynamics $\Phi(\tau_{k+1},\tau_k)$ to translate the process from a state at time $k$ to future state at $k+1$. This matrix assumes no input is being imparted, but a convolution can be used to describe the time varying input. The STM follows these dynamics:
%
\begin{align}
& \frac{d}{d\tau} \Phi(\tau,\tau_k) = A(\tau) \Phi(\tau,\tau_k), \quad \forall k \in \mathcal{K}
\end{align}
Additionally, the STM has the semigroup, inverse, and identity properties which become useful in the derivation:
\begin{align}
	\Phi(t,s) &= \Phi(t, \gamma)\Phi(\gamma, s) \\
	\Phi(t,s)^{-1} &= \Phi(s,t) \\
	\Phi(s,s) &= \mathbb{I}_{n \times n}
\end{align}
for arbitrary timing parameters $t, \gamma, s$. We can take advantage of this property during the discretization steps to minimize some computation. A general homogeneous solution for a system defined by $\dot{\mathbf{x}}$ using the STM is the following:

\begin{align}
	\text{given that} \ \ \mathbf{x}(\tau) &= \Phi(\tau, \tau_k) \mathbf{x}(\tau_k)\\
	\frac{d}{d\tau}\mathbf{x}(\tau) &= \dot{\Phi}(\tau, \tau_k) \mathbf{x}(\tau_k) = A(\tau)\mathbf{x}(\tau) \\ 
	& = A(\tau) \Phi(\tau, \tau_k) \mathbf{x}(\tau_k)
\end{align}
Integration leads to the following fact
\begin{align}
	\mathbf{x}(\xi) &= \mathbf{x}(\tau_k) + \int_{\tau_k}^\xi A(\xi) \Phi(\xi, \tau_k) \mathbf{x}(\tau_k) d\xi \\
	&= \left( \mathbb{I}_{n\times n} + \int_{\tau_k}^\xi A(\xi) \Phi(\xi, \tau_k) d\xi \right)  \mathbf{x}(\tau_k)
\end{align}
Therefore the arbitrary state transition mapping from time $\tau_k$ to $\xi$ can be represented as the following:
\begin{align}
	\Phi(\xi, \tau_k) = \mathbb{I}_{n\times n} + \int_{\tau_k}^\xi A(\xi) \Phi(\tau, \tau_k) d\xi, \quad \forall \xi \in \ [\tau_k, \tau_{k+1}]
\end{align}

Recall our continuous LTV system dynamics expression $\mathbf{x}^\prime(\tau) =  A(\tau)\mathbf{x} + B(\tau)\mathbf{u} + \mathbf{z}(\tau) + \Sigma(\tau)\eta$. Employing our control FOH, we want to form this as the following discrete time system:
\begin{align}
	\mathbf{x}_{k+1} = F_k\mathbf{x_k} + G^-_k\mathbf{u_k} + G^+_k\mathbf{u_{k+1}} + \bar{\mathbf{z}}_k + \bar{\Sigma}_k\eta
\end{align}
Converting the continuous time dynamics to discrete time dynamics, we perform a series of convolution integrals to define the impact of the transformations over each discrete time step. The continuous linear time invariant discretization form is usually written as $G=\int_{0}^{dt} e^{A \tau} d \tau B$, but given the LTV dynamics and our FOH control assumption, we reformulate as:
%
\begin{subequations}
\label{disc}
 \begin{align}
 F_k &\triangleq  \Phi(\tau_{k+1},\tau_k)\\
 %
 G^-_k &\triangleq \int_{\tau_k}^{\tau_{k+1}}  \Phi(\tau_{k+1},\xi) \alpha_k(\xi)B(\xi) d\xi\\
 %
 &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}}  \Phi^{-1}(\xi,\tau_{k}) \alpha_k(\xi)B(\xi) d\xi\\
 %
 G^+_k &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}}  \Phi^{-1}(\xi,\tau_{k}) \beta_k(\xi)B(\xi) d\xi\\
 %
 \bar{\Sigma}_k &\triangleq  F_k \int_{\tau_k}^{\tau_{k+1}} \Phi^{-1}(\xi,\tau_{k}) \Sigma(\xi) d\xi\\
 %
 \bar{\mathbf{z}}_k &\triangleq F_k \int_{\tau_k}^{\tau_{k+1}} \Phi^{-1}(\xi,\tau_{k}) \mathbf{z}(\xi) d\xi
\end{align}
\end{subequations}

It should be noted that the number of temporal nodes $K$, where $\mathcal{K} \in \mathbb{Z}^K$, chosen for this problem to be evaluated at does not affect the accuracy of the solution, only the optimality. An optimization solution where $K=10$ will still accurately land the vehicle within all the constraints defined, but may do so in more time and with larger cost than the same problem solved at $K=25$. However, the former is computed faster and generally produces a cost quite close to the higher temporal-density solution depending on the problem statement.

\section{Successive Form, Trust Regions and Relaxations}

In order to solve a non-convex problem, we iteratively solve a sequence of related convex subproblems. However, before we can reach a concluding framework, we must consider trust regions and dynamic relaxations. In order to make sure that this successive framework stays bounded and feasible through this convergence process, we must bound the divergence of state and inputs from one iteration to another. Unbounded problems can arise from constraints that admit an unbounded cost. To mitigate this issue, we augment the cost function with soft trust regions about the previous iterate's information. Let us define these deviations at iteration $i$ as such:
\begin{align}
& \delta \mathbf{x}_k^i \triangleq \mathbf{x}_k^i - \mathbf{x}_k^{i-1} \\
& \delta \mathbf{u}_k^i \triangleq \mathbf{u}_k^i - \mathbf{u}_k^{i-1}, \quad \forall k \in \mathcal{K}\\
& \delta \eta^i \triangleq \eta^i - \eta^{i-1}
\end{align}

We can then fabricate the following constraints with $\bm{\bar{\Delta}}^i \in \mathbb{R}^K$ and $\Delta_\eta^i \in \mathbb{R}$
\begin{align}
& \delta \mathbf{x}_k^i \cdot \delta \mathbf{x}_k^i + \delta \mathbf{u}_k^i \cdot \delta \mathbf{u}_k^i \leq \bar{\Delta}_k^i \\
& \delta \eta^i \cdot \delta \eta^i \leq \Delta_\eta^i
\end{align}

We can now append $w_\Delta^i \norm{{\bar{\Delta}}^i} + w_{\Delta_\eta} ||\Delta_\eta^i ||$ to the cost function to minimize input, state, and final time deviations and keeping their deviation bounded via constraint, where $w_\Delta^i$ and $w_{\Delta_\eta}$ are weighting scalars depending on the preferences of the scenario. While the norm magnitudes are bounded, we consider these soft constraints.
Given that the trust regions are centered about previous points $(\mathbf{x}_{k}^{i-1},\mathbf{u}_{k}^{i-1},\eta^{i-1})$, we must evaluate the Jacobian about the nonlinear trajectory beginning at $\mathbf{x}_{k}^{i-1}$. We can then use the FOH input vector $\mathbf{u}(\tau)$. Doing this $\forall k \in \mathcal{K}$ defines the aforementioned linearization path $(\hat{\mathbf{x}}, \hat{\mathbf{u}}, \hat{\eta})$. 


We now add a dynamic relaxation variable to discount artificial infeasibility. This is encountered during the convergence process when the linearization becomes infeasible. For example, if the dynamics are linearized about unrealistic conditions, the problem becomes dynamically inconsistent and will not produce solution. We modify the control such that we have guaranteed subproblem solutions that have non-empty feasible sets. This is encountered during the first couple iterations of a successive convexification due to poor initial trajectory or time-of-flight estimation. To get rid of this issue, we employ dynamic relaxation, where a slack variable is added to the dynamics in order to ``make room'' for the iteration to proceed. You can also think of this as a virtual control or dynamic padding. However, you can guess that this will inevitably be something we want to minimize in the cost function in order to make sure that our final trajectories are as dynamically consistent as possible. Therefore, we must now write our dynamics as follows: 
%
\begin{align}
& \mathbf{x}_{k+1}^i = F_k^i\mathbf{x}_k^i + G^{-,i}_k\mathbf{u}_k^i + G_k^{+,i}\mathbf{u}_{k+1}^i + \bar{\mathbf{z}}^i_k +\bar{\Sigma}_k^i\eta^i + \bm{\nu}_k^i
\end{align}
The right super script $^i$ indicates the iterate of the algorithm, where the subscript $_k$ of course means the ordered parameter entrance in our array shaped by $\mathcal{K}$.

Because we are going to use this in our cost function as a norm, we shall concatenate the time history of the slack variable as
\begin{align}
\bm{\nu}^i = 
	\begin{bmatrix}
	{\bm{\nu}_0^i}^T & \cdots & {\bm{\nu}^i_{K-2}}^T 
	\end{bmatrix}^T
\end{align}

And of course we augment the cost function again with $w_v \norm{\bm{\nu}^i}_1$. As the iteration continues, this value is minimized as the solution becomes more dynamically feasible. Therefore, the magnitude of this norm is indicative of a final solution in the successive iteration process.

\section{Convex Sub-Problem}
Now that we have linearized and convexified the proposed problem, we can put these components together as the full free-final-time problem shown in \ref{problem2} where we use the following objective function:
\begin{align}
	\min_{\eta^i, \mathbf{u}_k^i} \quad \eta^i + w_\Delta^i || \bm{\bar{\Delta}}^i ||_2 + w_{\Delta_\eta} || \Delta_\eta^i ||_1 + w_v || \bar{\bm{\nu}}^i ||_1
\end{align}

\subsection{Algorithm}
The goal is for the successive convexification algorithm \ref{Successive} to continue iterating until $\Delta_{tol}$ and $\nu_{tol}$ are met. We define these by the magnitude of each vector. Their magnitudes are checked at the end of each iteration of the routine. Additionally, to ensure boundedness on the trust regions and to prevent an admitted unbounded cost, we turn the cost weighting of the trust region up after each iteration.

\begin{algorithm}
\caption{Successive Convexification}\label{Successive}
\begin{algorithmic}[1]
\Procedure{SCvx}{$x_{ref}, u_{ref}, \eta_{ref}$}
\State Generate initial reference trajectory by linearly spanning states and inputs from initial conditions to terminal constraints.
\While{$ ||{\Delta}|| \geq \Delta_{tol} \quad \&\& \quad ||{\nu}|| \geq \nu_{tol} \quad \&\& \quad i \leq i_{max}$}
\State Compute $\bar{A}_k^{i-1}, \bar{B}_k^{i-1}, \bar{C}_k^{i-1}, \bar{\Sigma}_k^{i-1}, \bar{z}_k^{i-1}$ from $\mathbf{x}_k^{i-1}, \mathbf{u}_k^{i-1}, \eta^{i-1}$
\State Solve Problem 2 using $\mathbf{x}_k^{i-1}, \mathbf{u}_k^{i-1}, \eta^{i-1}, \bar{A}_k^{i-1}, \bar{B}_k^{i-1}, \bar{C}_k^{i-1}, \bar{\Sigma}_k^{i-1}, \bar{z}_k^{i-1}$
\State Store the newly found $\mathbf{x}_k^{i}, \mathbf{u}_k^{i}, \eta^{i}$
\State $w^{i+1}_\Delta = 1.7*w^{i}_\Delta$
\State $i++;$
\EndWhile 
\State \textbf{return} $\mathbf{x}, \mathbf{u}$
\EndProcedure
\end{algorithmic}
\end{algorithm}



\clearpage
\begin{mdframed}
\label{problem2}
\textbf{Problem 2: Discretized Convex Fixed-Final-Time Sub-Problem ($i^{th}$ iteration)}
\underline{Cost Function:}
\begin{equation*}
\min_{\eta^i, \mathbf{u}_k^i} \quad \eta^i + w_\Delta^i || \bm{\bar{\Delta}}^i ||_2 + w_{\Delta_\eta} || \Delta_\eta^i ||_1 + w_v || \bar{\bm{\nu}}^i ||_1
\end{equation*}
%
\underline{Boundary Conditions:}  
\begin{align*}
m_0 &= m_0, &^\mathcal{N}\mathbf{r}_0 &= \mathbf{r}_0, & ^\mathcal{N}\mathbf{v}_0 &= \mathbf{v}_0, & \boldsymbol{\sigma}_{\mathcal{B/N}_0} &= {\boldsymbol{\sigma}_0}, \quad ^\mathcal{B}\boldsymbol{\omega}_{\mathcal{B/N}_0} = \boldsymbol{\omega}_0 \\
\quad ^\mathcal{N}\mathbf{r}_{K-1} &= \mathbf{0}, & ^\mathcal{N}\mathbf{v}_{K-1} &= \mathbf{0}, & \boldsymbol{\sigma}_{\mathcal{B/N}_{K-1}} &= \mathbf{0}, & ^\mathcal{B}\boldsymbol{\omega}_{\mathcal{B/N}_{K-1}} &= \mathbf{0}
\end{align*}
%
\underline{Dynamics:}  
\begin{align*}
& \mathbf{x}_{k+1}^i = F_k^i\mathbf{x}_k^i + G^{-,i}_k\mathbf{u}_k^i + G_k^{+,i}\mathbf{u}_{k+1}^i + \bar{\mathbf{z}}^i_k +\bar{\Sigma}_k^i\eta^i + \bm{\nu}_k^i
\end{align*}
%
\underline{State and Control Constraints:}
\begin{align*}
m_{dry} - m_k & \leq 0 \\
|| [\hat{\bm{n}}_2 \ \ \hat{\bm{n}}_3 ]^T \mathbf{r}_k \lvert\lvert_2 \ \tan{\gamma_{gs}}  - \hat{\bm{n}}_1^T \mathbf{r}_k & \leq 0 \\
%
\left \lVert \boldsymbol{\sigma}_{\mathcal{B/N}_k} \right \lVert_2 &\leq \tan \left( \frac{\psi_{max}}{4} \right) \\
%
|| \bm{\omega}_{\mathcal{B/N}_k} ||_2 & \leq \omega_{max}
\end{align*}
%
\underline{Control Constraints:}  
\begin{align*}
F_{min} &\leq \Xi_k^i\mathbf{u}_k^i \\
|| \mathbf{u}_k^i ||_2 &\leq F_{max} \\
\cos(\delta_{max}) || \mathbf{u}_k^i ||_2 &\leq \hat{\bm{b}}_1^T \mathbf{u}_k^i
% || \delta_{\text{TVC}_{k+1}} - \delta_{\text{TVC}_{k}} ||_2 &\leq \frac{ \eta^i}{K}\dot{\delta}_{\text{TVC}_{max}}
\end{align*}
%
\underline{Trust Regions:}  
\begin{align*}
& ||{\delta \mathbf{x}_k^i}^T  \delta \mathbf{x}_k^i + {\delta \mathbf{u}_k^i}^T \delta \mathbf{u}_k^i ||_2 \leq \bar{\Delta}_k^i \\
& || \delta \eta^i ||_2 \leq \Delta_\eta^i
\end{align*}
\end{mdframed}

